{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/todoo123/todoo123/blob/circleci-project-setup/escfinalproject_SSL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c235fbe8",
      "metadata": {
        "id": "c235fbe8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "# !pip install category_encoders\n",
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('/content/train.parquet')\n",
        "test = pd.read_parquet('/content/test.parquet')"
      ],
      "metadata": {
        "id": "W2WDVl1bsVcy"
      },
      "id": "W2WDVl1bsVcy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9d8cdda6",
      "metadata": {
        "id": "9d8cdda6"
      },
      "outputs": [],
      "source": [
        "def days_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    # day 변수 처리, month, day를 하나의 변수로 합치고자함 \n",
        "    def to_days(x):\n",
        "        month_to_days = {1:0, 2:31, 3:60, 4:91, 5:121, 6:152, 7:182, 8:213, 9:244, 10:274, 11:305, 12:335}\n",
        "        return month_to_days[x]\n",
        "\n",
        "    train.loc[:, 'Day'] = train['Month'].apply(lambda x: to_days(x))\n",
        "    train['Day'] = train['Day'] + train['Day_of_Month']\n",
        "\n",
        "    test.loc[:, 'Day'] = test['Month'].apply(lambda x: to_days(x))\n",
        "    test['Day'] = test['Day'] + test['Day_of_Month']\n",
        "\n",
        "    train = train.astype({'Day':object})\n",
        "    test = test.astype({'Day':object})\n",
        "\n",
        "    print(\"Day Done.\")\n",
        "    return train, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a97fa663",
      "metadata": {
        "id": "a97fa663"
      },
      "outputs": [],
      "source": [
        "def cid_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    airline_to_cid = {}\n",
        "    for _, row in train[(~train['Carrier_ID(DOT)'].isnull() & ~train['Airline'].isnull())].iterrows():\n",
        "        airline_to_cid[row['Airline']] = row['Carrier_ID(DOT)']\n",
        "    # 복구하기\n",
        "    def to_cid(x):\n",
        "        return airline_to_cid[x]\n",
        "\n",
        "    cond1 = train['Carrier_ID(DOT)'].isnull()\n",
        "    cond2 = ~train['Airline'].isnull()\n",
        "    train.loc[cond1&cond2, 'Carrier_ID(DOT)'] = train.loc[cond1&cond2, 'Airline'].apply(lambda x: to_cid(x))\n",
        "\n",
        "    train = train.dropna(subset=['Carrier_ID(DOT)'], how='any', axis=0)\n",
        "\n",
        "    # (Test Data Only)\n",
        "    # Airline, Carrier_Code 둘 다 없으면 최빈 값으로 대체\n",
        "    NaN_col = ['Carrier_ID(DOT)']\n",
        "    cond1 = test['Airline'].isnull()\n",
        "    cond2 = test['Carrier_ID(DOT)'].isnull()\n",
        "\n",
        "    for col in NaN_col:\n",
        "        mode = test[col].mode()[0]\n",
        "        test.loc[cond1&cond2, col] = mode\n",
        "\n",
        "    # 나머진 Airline에서 대체\n",
        "    cond1 = test['Carrier_ID(DOT)'].isnull()\n",
        "    cond2 = ~test['Airline'].isnull()\n",
        "    test.loc[cond1&cond2, 'Carrier_ID(DOT)'] = test.loc[cond1&cond2, 'Airline'].apply(lambda x: to_cid(x))\n",
        "\n",
        "    print(\"Cid Done.\")\n",
        "    \n",
        "    return train, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bc5ab0ca",
      "metadata": {
        "id": "bc5ab0ca"
      },
      "outputs": [],
      "source": [
        "def drop_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    \n",
        "    col_drop = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', 'Origin_Airport', 'Destination_Airport', 'Carrier_Code(IATA)', 'Airline', 'Origin_State', 'Destination_State']\n",
        "    train = train.drop(col_drop, axis=1)\n",
        "    test = test.drop(col_drop, axis=1)\n",
        "    print(\"Drop Done.\")\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9833d6c6",
      "metadata": {
        "id": "9833d6c6"
      },
      "outputs": [],
      "source": [
        "def EAD_EDT_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    \n",
        "    # Estimated Departure Time (EDT), Estimated Arrival Time (EAT) 복구\n",
        "    # 출발하는 공항과 도착하는 공항의 평균 비행시간을 이용하여 복구\n",
        "    def to_minutes(x):\n",
        "        x = int(x)\n",
        "        x = str(x)\n",
        "        if len(x) > 2:\n",
        "            hours, mins = int(x[:-2]), int(x[-2:])\n",
        "        else:\n",
        "            hours, mins = 0, int(x[-2:])\n",
        "        return hours*60+mins\n",
        "\n",
        "    estimated_times = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
        "\n",
        "    for ET in estimated_times:\n",
        "        cond = ~train[ET].isnull()\n",
        "        train.loc[cond, ET] = train.loc[cond, ET].apply(lambda x: to_minutes(x))\n",
        "        cond2 = ~test[ET].isnull()\n",
        "        test.loc[cond2, ET] = test.loc[cond2, ET].apply(lambda x: to_minutes(x))\n",
        "\n",
        "    train = train.dropna(subset=['Estimated_Arrival_Time', 'Estimated_Departure_Time'], how ='all', axis=0)\n",
        "\n",
        "    time_flying = defaultdict(int)\n",
        "    time_number = defaultdict(int)\n",
        "\n",
        "    cond_arr2 = ~train['Estimated_Arrival_Time'].isnull()\n",
        "    cond_dep2 = ~train['Estimated_Departure_Time'].isnull()\n",
        "\n",
        "    for _, row in train.loc[cond_arr2 & cond_dep2, :].iterrows():\n",
        "        OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
        "        time_flying[(OAID,DAID)] += (row['Estimated_Arrival_Time'] - row['Estimated_Departure_Time'])%1440 # 하루 최대는 1440분\n",
        "        time_number[(OAID,DAID)] += 1\n",
        "\n",
        "\n",
        "    for key in time_flying.keys():\n",
        "        time_flying[key] /= time_number[key]\n",
        "\n",
        "    for index, row in train.loc[train['Estimated_Departure_Time'].isnull(),].iterrows():\n",
        "        OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
        "        train.loc[index,'Estimated_Departure_Time'] = \\\n",
        "            (train.loc[index]['Estimated_Arrival_Time'] - time_flying[(OAID, DAID)])%1440\n",
        "\n",
        "    for index, row in train.loc[train['Estimated_Arrival_Time'].isnull(),].iterrows():\n",
        "        OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
        "        train.loc[index,'Estimated_Arrival_Time'] = \\\n",
        "            (train.loc[index]['Estimated_Departure_Time'] + time_flying[(OAID, DAID)])%1440\n",
        "        \n",
        "    # (Test Data Only)\n",
        "    # 둘 다 없으면 최빈값으로 대체\n",
        "    cond_1 = test['Estimated_Departure_Time'].isnull()\n",
        "    cond_2 = test['Estimated_Arrival_Time'].isnull()\n",
        "\n",
        "    mode = test['Estimated_Departure_Time'].mode()[0]\n",
        "    mode2 = test['Estimated_Arrival_Time'].mode()[0]\n",
        "    test.loc[cond_1&cond_2, ['Estimated_Departure_Time', 'Estimated_Arrival_Time']] = mode, mode2\n",
        "\n",
        "\n",
        "    # Departure만 없을 때,\n",
        "    for index, row in test.loc[test['Estimated_Departure_Time'].isnull(),].iterrows():\n",
        "        OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
        "        test.loc[index,'Estimated_Departure_Time'] = \\\n",
        "            (test.loc[index]['Estimated_Arrival_Time'] - time_flying[(OAID, DAID)])%1440\n",
        "\n",
        "\n",
        "    # Arrival만 없을 때,\n",
        "    for index, row in test.loc[test['Estimated_Arrival_Time'].isnull(),].iterrows():\n",
        "        OAID, DAID = row['Origin_Airport_ID'], row['Destination_Airport_ID']\n",
        "        test.loc[index,'Estimated_Arrival_Time'] = \\\n",
        "            (test.loc[index]['Estimated_Departure_Time'] + time_flying[(OAID, DAID)])%1440\n",
        "\n",
        "\n",
        "    # 모두 int로 바꾼다.\n",
        "    estimated_times = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
        "    train = train.astype({'Estimated_Departure_Time':int, 'Estimated_Arrival_Time':int})\n",
        "    test = test.astype({'Estimated_Departure_Time':int, 'Estimated_Arrival_Time':int})\n",
        "    for ET in estimated_times:\n",
        "        train.loc[train[ET] == 1440, ET] = 0\n",
        "        test.loc[test[ET] == 1440, ET] = 0\n",
        "\n",
        "    # EDT, EAT 48개의 bins에 담으면 된다. 1440(60*24) 계니까, 48씩 끊어서 하면 될 듯\n",
        "    estimate_times = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
        "    names = {'Estimated_Departure_Time':'EDT', 'Estimated_Arrival_Time':'EAT'}\n",
        "    for ET in estimated_times:\n",
        "        for i in range(48):\n",
        "            train.loc[train[ET].between(i*30, (i+1)*30, 'left'), names[ET]] = i\n",
        "            test.loc[test[ET].between(i*30, (i+1)*30, 'left'), names[ET]] = i\n",
        "\n",
        "    train = train.astype({'EDT':int, 'EAT':int})\n",
        "    test = test.astype({'EDT':int, 'EAT':int})\n",
        "\n",
        "    train = train.drop(['Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
        "    test = test.drop(['Estimated_Departure_Time', 'Estimated_Arrival_Time'], axis=1)\n",
        "    \n",
        "    print(\"EAT_EDT Done.\")\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bc87a464",
      "metadata": {
        "id": "bc87a464"
      },
      "outputs": [],
      "source": [
        "def travel_time_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    \n",
        "    train['Estimated_Travel_Time']=train.EAT-train.EDT\n",
        "    test['Estimated_Travel_Time']=test.EAT-test.EDT\n",
        "    def eliminate_outliers(df, a_col, b_col, threshold=1.5):\n",
        "        correlation = df[a_col].corr(df[b_col])\n",
        "        if correlation < 0:\n",
        "            raise ValueError(\"negative\")\n",
        "\n",
        "        q_low = df[a_col].quantile(0.05)\n",
        "        q_high = df[a_col].quantile(0.95)\n",
        "        iqr = q_high - q_low\n",
        "\n",
        "        lower_bound = q_low - threshold * iqr\n",
        "        upper_bound = q_high + threshold * iqr\n",
        "\n",
        "        filtered_df = df.copy() \n",
        "        filtered_df.loc[(df[a_col] < lower_bound) | (df[a_col] > upper_bound), a_col] = np.nan\n",
        "        \n",
        "\n",
        "        return filtered_df\n",
        "    #Estimated_Travel_Time outlier np.nan으로 바뀐상태. drop.na하면 될듯\n",
        "    train = eliminate_outliers(train, 'Estimated_Travel_Time', 'Distance')\n",
        "    train = train.dropna(subset=['Estimated_Travel_Time'])\n",
        "    test  = eliminate_outliers(test, 'Estimated_Travel_Time', 'Distance')\n",
        "    \n",
        "    print('Travel_Time Done')\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2b047415",
      "metadata": {
        "id": "2b047415"
      },
      "outputs": [],
      "source": [
        "def distance_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    for i in range(51):\n",
        "        train.loc[train['Distance'].between(i*100, (i+1)*100, 'left'), 'Distance'] = i\n",
        "        test.loc[test['Distance'].between(i*100, (i+1)*100, 'left'), 'Distance'] = i\n",
        "\n",
        "    train = train.astype({'Distance':int})\n",
        "    test = test.astype({'Distance':int})\n",
        "\n",
        "    train = train.astype({'Carrier_ID(DOT)':int})\n",
        "    test = test.astype({'Carrier_ID(DOT)':int})\n",
        "    \n",
        "    print(\"distance Done.\")\n",
        "    \n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7d5b98c8",
      "metadata": {
        "id": "7d5b98c8"
      },
      "outputs": [],
      "source": [
        "def holidays_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    def holidays(x):\n",
        "        # sig는 특정 공휴일이 들어 있는 구간 구분 용도 \n",
        "        # sig 0은 어떤 공휴일에도 속하지 않음\n",
        "        # 나머지는 위의 순서를 따름\n",
        "        # 휴일 기간은 뇌피셜로 공휴일을 가운데 둔 5일 정도 잡음\n",
        "        sig = 0\n",
        "        if 364<=x or x<=2:  #sig =1 = 양력 설날\n",
        "            sig = 1\n",
        "        # 음력 설날은 계속 변해서 어떻게 해야 할지 모르겠음 일단 sig=2=음력설날\n",
        "    #     if 58<= x and x<=62:#sig=3= 사육제\n",
        "    #         sig = 3\n",
        "    #     if 78<= x and x<=82: # 춘분 시즌\n",
        "    #         sig= 4\n",
        "    #     if 91<= x and x<=95: #라마단\n",
        "    #         sig = 5\n",
        "    #     if 104<= x and x<=108: # 성목요일,좋은 금요일, 성 토요일, 부활절 합침\n",
        "    #         sig = 6\n",
        "    #     if 122<= x and x<=126: # Eid al-Fitr\n",
        "    #         sig = 7\n",
        "    #     if 143<= x and x<=147: # 그리스도 승천일\n",
        "    #         sig = 8\n",
        "        if 174<= x and x<=178: # 여행 시즌\n",
        "            sig = 9\n",
        "        if 184<= x and x<=188: # 각 나라 독립 기념일\n",
        "            sig = 10\n",
        "    #     if 189<= x and x<=193: # 장난의 향연\n",
        "    #         sig = 11\n",
        "    #     if 226<= x and x<=230: #마리아의 가정 \n",
        "    #         sig = 12\n",
        "    #     if 266<= x and x<=270: # 춘분 시즌\n",
        "    #         sig = 13\n",
        "    #     if 279<= x and x<=283: #예언자 무함마드 탄생일 \n",
        "    #         sig = 14\n",
        "    #     if 303<= x and x<=307: # 모든 성도의 하루, 위령일 합침\n",
        "    #         sig = 15\n",
        "        if 357<= x and x<=361: # 크리스마스 여행 시즌\n",
        "            sig = 16\n",
        "        return sig\n",
        "    \n",
        "    train.loc[:, 'Holidays'] = train['Day'].apply(lambda x: holidays(x))\n",
        "\n",
        "\n",
        "    test.loc[:, 'Holidays'] = test['Day'].apply(lambda x: holidays(x))\n",
        "\n",
        "\n",
        "    train = train.astype({'Holidays':object})\n",
        "    test = test.astype({'Holidays':object})\n",
        "\n",
        "    print(\"Holidays Done.\")\n",
        "    \n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4b92c4af",
      "metadata": {
        "id": "4b92c4af"
      },
      "outputs": [],
      "source": [
        "def airport_mean_encode_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    \n",
        "    df = train[train['Delay'].notnull()][['Destination_Airport_ID','Origin_Airport_ID','Delay']].copy()\n",
        "    df['Delay'] = df['Delay'].apply(lambda x: 1 if x ==\"Delayed\" else 0)\n",
        "    df_grouped = df.groupby(['Destination_Airport_ID','Origin_Airport_ID']).mean()\n",
        "    df_grouped.reset_index(inplace = True)\n",
        "\n",
        "    df_grouped.rename(columns = {'Delay':'Delay_mean'},inplace = True)\n",
        "    train_df = pd.merge(train, df_grouped, how = 'left',on = ['Destination_Airport_ID','Origin_Airport_ID'])\n",
        "    test_df = pd.merge(test, df_grouped, how = 'left',on = ['Destination_Airport_ID','Origin_Airport_ID'])\n",
        "    \n",
        "    test_df[test_df['Delay_mean'].isnull()] = 0  \n",
        "    train_df[train_df['Delay_mean'].isnull()] = 0\n",
        "    \n",
        "    train_df['Delay_mean'] = train_df['Delay_mean'].apply(lambda x: int(x*100))\n",
        "    test_df['Delay_mean'] = test_df['Delay_mean'].apply(lambda x: int(x*100))\n",
        "    \n",
        "    print('Mean encoding Done.')\n",
        "    \n",
        "    return train_df, test_df\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d7d9e290",
      "metadata": {
        "id": "d7d9e290"
      },
      "outputs": [],
      "source": [
        "def final_data_process(df_train, df_test):\n",
        "    train = df_train.copy()\n",
        "    test  = df_test.copy()\n",
        "    \n",
        "    train.loc[:, 'Delay_num'] = train['Delay'].apply(lambda x: 1 if x==\"Delayed\" else 0)\n",
        "\n",
        "    train_x = train.drop(columns=['ID', 'Delay', 'Delay_num'])\n",
        "    train_y = train['Delay_num']\n",
        "    test_x = test.drop(columns=['ID'])\n",
        "\n",
        "    print('Training Prepared.')\n",
        "    return train_x, train_y, test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ea4f464c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "ea4f464c",
        "outputId": "eb1347f1-e57c-4aa8-abbf-dd99290a1122"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7e2911253a4f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sample_submission.csv'"
          ]
        }
      ],
      "source": [
        "# sample_submission = pd.read_csv('./sample_submission.csv')\n",
        "# test   = pd.read_csv('./test.csv')\n",
        "# train   = pd.read_csv('./train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "ae03805d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae03805d",
        "outputId": "932965da-eae2-4785-edce-5580217a7a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Day Done.\n",
            "Cid Done.\n",
            "Drop Done.\n",
            "EAT_EDT Done.\n",
            "Travel_Time Done\n",
            "distance Done.\n",
            "Holidays Done.\n",
            "Mean encoding Done.\n"
          ]
        }
      ],
      "source": [
        "train_1, test_1 = days_process(train, test)\n",
        "train_2, test_2 = cid_process(train_1, test_1)\n",
        "train_3, test_3 = drop_process(train_2, test_2)\n",
        "train_4, test_4 = EAD_EDT_process(train_3, test_3)\n",
        "train_5, test_5 = travel_time_process(train_4, test_4)\n",
        "train_6, test_6 = distance_process(train_5, test_5)\n",
        "train_7, test_7 = holidays_process(train_6, test_6)\n",
        "train_8, test_8 = airport_mean_encode_process(train_7, test_7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "tofE464_2rYK",
        "outputId": "5a190447-2013-44e5-8dd7-a48b15fbda94"
      },
      "id": "tofE464_2rYK",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  ID  Origin_Airport_ID  Destination_Airport_ID  Distance  \\\n",
              "0       TRAIN_000001              13930                   14869        12   \n",
              "1       TRAIN_000002              11057                   12953         5   \n",
              "2       TRAIN_000003              12892                   11618        24   \n",
              "3       TRAIN_000004              14771                   10157         2   \n",
              "4                  0                  0                       0         0   \n",
              "...              ...                ...                     ...       ...   \n",
              "944204  TRAIN_999995              13930                   14100         6   \n",
              "944205  TRAIN_999996              11637                   13487         2   \n",
              "944206  TRAIN_999997              13796                   12191        16   \n",
              "944207  TRAIN_999998              10693                   10397         2   \n",
              "944208  TRAIN_999999              14635                   11433        10   \n",
              "\n",
              "        Carrier_ID(DOT) Tail_Number Delay  Day  EDT  EAT  \\\n",
              "0                 20304      N125SY  None  228   15   20   \n",
              "1                 19805      N103US  None  250   32   36   \n",
              "2                 19977      N595UA  None  192   18   35   \n",
              "3                 20304      N161SY  None   11   18   20   \n",
              "4                     0           0     0    0    0    0   \n",
              "...                 ...         ...   ...  ...  ...  ...   \n",
              "944204            19977      N477UA  None  262   19   25   \n",
              "944205            20304      N439SW  None  151   18   20   \n",
              "944206            19393      N230WN  None  180   16   27   \n",
              "944207            19790      N968DL  None  271   32   36   \n",
              "944208            19790      N695DL  None   86   36   41   \n",
              "\n",
              "        Estimated_Travel_Time Holidays  Delay_mean  \n",
              "0                         5.0        0          21  \n",
              "1                         4.0        0          17  \n",
              "2                        17.0        0          23  \n",
              "3                         2.0        0          21  \n",
              "4                         0.0        0           0  \n",
              "...                       ...      ...         ...  \n",
              "944204                    6.0        0          20  \n",
              "944205                    2.0        0          11  \n",
              "944206                   11.0        0          10  \n",
              "944207                    4.0        0          14  \n",
              "944208                    5.0        0          11  \n",
              "\n",
              "[944209 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fc031a9-4fca-48fd-a45e-1a23e58ed900\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Origin_Airport_ID</th>\n",
              "      <th>Destination_Airport_ID</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Carrier_ID(DOT)</th>\n",
              "      <th>Tail_Number</th>\n",
              "      <th>Delay</th>\n",
              "      <th>Day</th>\n",
              "      <th>EDT</th>\n",
              "      <th>EAT</th>\n",
              "      <th>Estimated_Travel_Time</th>\n",
              "      <th>Holidays</th>\n",
              "      <th>Delay_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_000001</td>\n",
              "      <td>13930</td>\n",
              "      <td>14869</td>\n",
              "      <td>12</td>\n",
              "      <td>20304</td>\n",
              "      <td>N125SY</td>\n",
              "      <td>None</td>\n",
              "      <td>228</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_000002</td>\n",
              "      <td>11057</td>\n",
              "      <td>12953</td>\n",
              "      <td>5</td>\n",
              "      <td>19805</td>\n",
              "      <td>N103US</td>\n",
              "      <td>None</td>\n",
              "      <td>250</td>\n",
              "      <td>32</td>\n",
              "      <td>36</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_000003</td>\n",
              "      <td>12892</td>\n",
              "      <td>11618</td>\n",
              "      <td>24</td>\n",
              "      <td>19977</td>\n",
              "      <td>N595UA</td>\n",
              "      <td>None</td>\n",
              "      <td>192</td>\n",
              "      <td>18</td>\n",
              "      <td>35</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_000004</td>\n",
              "      <td>14771</td>\n",
              "      <td>10157</td>\n",
              "      <td>2</td>\n",
              "      <td>20304</td>\n",
              "      <td>N161SY</td>\n",
              "      <td>None</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944204</th>\n",
              "      <td>TRAIN_999995</td>\n",
              "      <td>13930</td>\n",
              "      <td>14100</td>\n",
              "      <td>6</td>\n",
              "      <td>19977</td>\n",
              "      <td>N477UA</td>\n",
              "      <td>None</td>\n",
              "      <td>262</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944205</th>\n",
              "      <td>TRAIN_999996</td>\n",
              "      <td>11637</td>\n",
              "      <td>13487</td>\n",
              "      <td>2</td>\n",
              "      <td>20304</td>\n",
              "      <td>N439SW</td>\n",
              "      <td>None</td>\n",
              "      <td>151</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944206</th>\n",
              "      <td>TRAIN_999997</td>\n",
              "      <td>13796</td>\n",
              "      <td>12191</td>\n",
              "      <td>16</td>\n",
              "      <td>19393</td>\n",
              "      <td>N230WN</td>\n",
              "      <td>None</td>\n",
              "      <td>180</td>\n",
              "      <td>16</td>\n",
              "      <td>27</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944207</th>\n",
              "      <td>TRAIN_999998</td>\n",
              "      <td>10693</td>\n",
              "      <td>10397</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>N968DL</td>\n",
              "      <td>None</td>\n",
              "      <td>271</td>\n",
              "      <td>32</td>\n",
              "      <td>36</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944208</th>\n",
              "      <td>TRAIN_999999</td>\n",
              "      <td>14635</td>\n",
              "      <td>11433</td>\n",
              "      <td>10</td>\n",
              "      <td>19790</td>\n",
              "      <td>N695DL</td>\n",
              "      <td>None</td>\n",
              "      <td>86</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>944209 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc031a9-4fca-48fd-a45e-1a23e58ed900')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fc031a9-4fca-48fd-a45e-1a23e58ed900 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fc031a9-4fca-48fd-a45e-1a23e58ed900');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_8.info()\n",
        "\n",
        "\n",
        "# Origin_Airport_ID, Destination_Airport_ID 의 관계가 Delay_mean 에 반영됨.\n",
        "# Distance 는 연속형으로, 투입 가능\n",
        "# Carrier_ID(DOT) 범주형으로 판단되는 숫자형으로 mean encoding 과 같은 preprocessing 필요함.\n",
        "# Tail_Number 범주형으로 판단되는 숫자형으로 mean encoding 과 같은 preprocessing 필요함.\n",
        "# Delay target 변수 one-hot encoding\n",
        "# day 일 단위로 범주화해버림. - preprocessing 필요함\n",
        "# EDT, EAT 의 경우, 연속형으로 예측되는 비행 거리를 표시하는 것 같은데 - 이 또한 extimated_Travel_Time 이 반영하는 것 같다.(모델링 과정에서 뺄 수 있을 것 같음)\n",
        "# Holidays - 휴일인 경우 indexing 해버린 것 같음 - 일별로 범주화 했는데 의미있나?\n",
        "# Delay_mean 은 Origin_Airport_ID 와 Destination_Airport_ID 가 매치되었을 때 나타나는 특징의 proxy 임. \n",
        "\n",
        "\n",
        "# todo\n",
        "# Carrier_ID(DOT) 범주형으로 판단되는 숫자형으로 mean encoding 과 같은 preprocessing 필요함.\n",
        "# Tail_Number 범주형으로 판단되는 숫자형으로 mean encoding 과 같은 preprocessing 필요함.\n",
        "# Delay target 변수 one-hot encoding\n",
        "# day 일 단위로 범주화해버림. - preprocessing 필요함\n",
        "# Holidays - 휴일인 경우 indexing 해버린 것 같음 - 일별로 범주화 했는데 의미있나?\n",
        "\n",
        "# 일단은 todo 에 있는 모든 칼럼들을 이용해서 catboost encoding 적용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn6Yf_zdwBiW",
        "outputId": "f9e9724d-e011-47be-b240-8fae1604757c"
      },
      "id": "tn6Yf_zdwBiW",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 944209 entries, 0 to 944208\n",
            "Data columns (total 13 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   ID                      944209 non-null  object \n",
            " 1   Origin_Airport_ID       944209 non-null  int64  \n",
            " 2   Destination_Airport_ID  944209 non-null  int64  \n",
            " 3   Distance                944209 non-null  int64  \n",
            " 4   Carrier_ID(DOT)         944209 non-null  int64  \n",
            " 5   Tail_Number             944209 non-null  object \n",
            " 6   Delay                   242171 non-null  object \n",
            " 7   Day                     944209 non-null  object \n",
            " 8   EDT                     944209 non-null  int64  \n",
            " 9   EAT                     944209 non-null  int64  \n",
            " 10  Estimated_Travel_Time   944209 non-null  float64\n",
            " 11  Holidays                944209 non-null  object \n",
            " 12  Delay_mean              944209 non-null  int64  \n",
            "dtypes: float64(1), int64(7), object(5)\n",
            "memory usage: 100.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_8 = train_8.replace(\"Delayed\", 1)\n",
        "train_8 = train_8.replace(\"Not_Delayed\", 0)\n",
        "\n",
        "labeled_data = train_8[train_8[\"Delay\"].notnull()]\n",
        "train_cat = labeled_data[[\"Carrier_ID(DOT)\",\"Tail_Number\",\"Day\",\"Holidays\"]].astype(str)\n",
        "target_cat = labeled_data[[\"Delay\"]].astype(int)\n",
        "CBE_encoder = ce.CatBoostEncoder(handle_missing = \"return_nan\")\n",
        "train_cbe = CBE_encoder.fit_transform(train_cat, target_cat)\n",
        "# test_cbe = CBE_encoder.transform(train_cat)"
      ],
      "metadata": {
        "id": "O-6pD9HZE5l0"
      },
      "id": "O-6pD9HZE5l0",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cbe.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa3tWloUPMK5",
        "outputId": "d184a0f4-d3be-4f1a-e4e0-8350a243ab8c"
      },
      "id": "Sa3tWloUPMK5",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Carrier_ID(DOT)', 'Tail_Number', 'Day', 'Holidays'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변경한 범주값을 원래 값에 매칭시켜 기존에 존재하던 unlabeled data 에도 매칭시키기 - 1. dictionary 만들기\n",
        "cat_dict = dict()\n",
        "\n",
        "for i in train_cbe.index:\n",
        "    for j in train_cbe.columns:\n",
        "        cat_dict[train_cat.loc[i,j]] = train_cbe.loc[i,j]"
      ],
      "metadata": {
        "id": "2u8LiTsTIkkk"
      },
      "id": "2u8LiTsTIkkk",
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변경한 범주값을 원래 값에 매칭시켜 기존에 존재하던 unlabeled data 에도 매칭시키기 - 1. dictionary 를 이용해 unlabeled data 에 적용\n",
        "for i in range(train_8.shape[0]):\n",
        "    for j in train_cbe.columns:\n",
        "        try:\n",
        "            train_8.loc[i,j] = cat_dict[f\"{train_8.loc[i,j]}\"]\n",
        "            \n",
        "        except KeyError:\n",
        "            train_8.loc[i,j] = None"
      ],
      "metadata": {
        "id": "sGSnkn1cRYCH"
      },
      "id": "sGSnkn1cRYCH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_8.info()"
      ],
      "metadata": {
        "id": "kkLJfdiuUecP"
      },
      "id": "kkLJfdiuUecP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split train data to train and valid dataset\n",
        "valid_final = train_8[train_8[\"Delay\"].notnull()].sample(frac = 0.2)\n",
        "final_df = train_8.drop(valid.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsN7Rd0oH2S9",
        "outputId": "8ade6f5e-4e3e-496b-9133-931c7e117aff"
      },
      "id": "rsN7Rd0oH2S9",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4         104\n",
              "5          20\n",
              "7         165\n",
              "9         226\n",
              "11         12\n",
              "         ... \n",
              "944172    285\n",
              "944173    123\n",
              "944178    284\n",
              "944194    221\n",
              "944201    365\n",
              "Name: Day, Length: 242171, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_final.astype(\"float64\")\n",
        "final_df.astype(\"float64\")\n",
        "\n",
        "ul_df = final_df.loc[final_df.Delay.isnull()].drop(['ID','Delay'], axis=1)\n",
        "l_df = final_df.loc[final_df.Delay.notnull()].drop(['ID'], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(l_df['Delay'])\n",
        "l_df['Delay'] = le.transform(l_df['Delay'])\n",
        "\n",
        "l_x = torch.tensor(l_df.drop(['Delay'], axis=1).values).type(torch.float32).to('cuda:0')  # 라벨 데이터 feature\n",
        "l_y = torch.tensor(l_df['Delay'].values).type(torch.float32).to('cuda:0')                 # 라벨 데이터 target\n",
        "u_x = torch.tensor(ul_df.values).type(torch.float32).to('cuda:0')                         # un 라벨 데이터\n",
        "\n",
        "print(le.classes_)\n",
        "\n",
        "# cuda form 으로 바꿔줌"
      ],
      "metadata": {
        "id": "2iWALVRjUwws"
      },
      "id": "2iWALVRjUwws",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, d_columns, d_model=128, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ff_activation = nn.ReLU()                 # Relu 활성화 함수\n",
        "        self.ff_batchnorm = nn.BatchNorm1d(d_model)    # 배치 정규화\n",
        "\n",
        "        self.ff_1 = nn.Linear(d_columns, d_model)\n",
        "        self.ff_2 = nn.Linear(d_model, d_model)\n",
        "        self.ff_3 = nn.Linear(d_model, d_model)\n",
        "        self.ff_4 = nn.Linear(d_model, d_model)\n",
        "        self.ff_5 = nn.Linear(d_model, d_model)        # 다중선형회귀 모형 5개 - 신경망 5겹\n",
        "\n",
        "        self.classification = nn.Sequential(           # 모듈들을 인수로 받아서 연속적으로 수행하는 method\n",
        "            nn.Linear(d_model, int(d_model/2)),\n",
        "            nn.BatchNorm1d(int(d_model/2)),\n",
        "            nn.Dropout(p=dropout),                     # 0.2 dropout - 신경망 중 일부를 랜덤 삭제 - 일반화 성능 향상\n",
        "            nn.GELU(),                                 # GELU 활성화 함수?\n",
        "            nn.Linear(int(d_model/2), int(d_model/4)), # 모델이 128 개 벡터에서 input-64개, output-32개로 감소\n",
        "            nn.BatchNorm1d(int(d_model/4)),            \n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(d_model/4), 1),              # for binary classification - input-8, output-1으로 \n",
        "                                                       # 해당 확률값을 이용해서 classification 문제를 풀 수 있게 함\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.ff_1(x)                              \n",
        "        x1 = self.ff_batchnorm(x1)                     # 위에서 정의한 배치 정규화\n",
        "        x1 = self.ff_activation(x1)                    # 위에서 정의한 RELU 활성화 함수\n",
        "\n",
        "        x2 = self.ff_2(x1)\n",
        "        x2 = self.ff_batchnorm(x2)\n",
        "        x2 = self.ff_activation(x2)\n",
        "\n",
        "        x3 = self.ff_3(torch.add(x1,x2))               # 벡터 덧셈 - 첫 번째와 두 번째 레이어의 output 을 더해서 연산 수행\n",
        "        x3 = self.ff_batchnorm(x3)\n",
        "        x3 = self.ff_activation(x3)\n",
        "\n",
        "        x4 = self.ff_4(x3)\n",
        "        x4 = self.ff_batchnorm(x4)\n",
        "        x4 = self.ff_activation(x4)\n",
        "\n",
        "        x5 = self.ff_5(torch.add(x3,x4))               # 위와 마찬가지의 방법 적용\n",
        "        x5 = self.ff_batchnorm(x5)\n",
        "        x5 = self.ff_activation(x5)                    # 5개의 layer 통과\n",
        "\n",
        "        logits = self.classification(x5)               # 분류를 위한 scalar 화\n",
        "        return F.sigmoid(logits).view(-1)              # sigmoid 함수에 넣고 그 값을 1차원으로 변경\n",
        "\n",
        "class CustomLoss(nn.Module):                           # custom 한 loss function dacon. \n",
        "    def __init__(self, xi):                            # 불균형 데이터셋을 위한 방법 중 하나 - custom 한 log loss function\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.xi = xi\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        return torch.mean(-1.0*((1-self.xi)*target*torch.log(output) + self.xi*(1-target)*torch.log(1-output)))"
      ],
      "metadata": {
        "id": "w1TmxSFGVJvw"
      },
      "id": "w1TmxSFGVJvw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = BaseModel(d_columns=8).to('cuda:0')\n",
        "student = BaseModel(d_columns=8).to('cuda:0')\n",
        "\n",
        "t_optimizer = optim.SGD(teacher.parameters(),lr=0.0001, momentum=0.9)           # 최적화는 SGD사용\n",
        "s_optimizer = optim.SGD(student.parameters(),lr=0.0001, momentum=0.9)\n",
        "\n",
        "criterion = CustomLoss(xi=0.725)                                                # 경험적으로 xi = 0.725 사용\n",
        "best_loss = np.inf\n",
        "patient = 0\n",
        "\n",
        "early_stop_epoch = 0\n",
        "tl_loss, sl_loss = [], []\n",
        "for epochs in tqdm(range(5000)):                                                # 5000 epoch\n",
        "    teacher.train()                                                             # 처음에 default 값 세팅 (둘다)\n",
        "    student.train()\n",
        "\n",
        "    t_optimizer.zero_grad()                                                     # 가중치 업데이트를 위한 기울기 초기화 - SGD 방법\n",
        "    s_optimizer.zero_grad()\n",
        "\n",
        "    s_l_pred = student(l_x)\n",
        "    s_l_loss = criterion(s_l_pred, l_y)\n",
        "\n",
        "    sl_loss.append(s_l_loss.item())                                             # pseudo label 을 이용한 student model 의 loss 기록(처음에는 default 값 기록)\n",
        "\n",
        "    t_u_pred = teacher(u_x)                                                     # unlabeled data 를 이용한 pseudo label\n",
        "    pseudo_y = (t_u_pred >= torch.FloatTensor([0.5]).to('cuda:0')).type(torch.float32)\n",
        "                                                                                # hard pseudo label - 0.5이상은 1 이하는 0 - 계산량 감소 위함\n",
        "    s_u_pred = student(u_x)                                                     # unlabeled data 를 이용한 student model 의 예측값\n",
        "    s_u_loss = criterion(s_u_pred, pseudo_y)                                    # pseudo label 을 이용한 student model 의 loss 기록(처음에는 default 값 기록)\n",
        "    s_u_loss.backward()                                                         # student model 의 역전파 수행\n",
        "    s_optimizer.step()                                                          # student model 의 parameter update(teacher model 의 예측값을 이용한)\n",
        "\n",
        "    s_l_pred_new = student(l_x)                                                 # pseudo label 로 학습한 student model 로 labeled data 예측\n",
        "    s_l_loss_new = criterion(s_l_pred_new, l_y)                                 # 위의 예측의 loss 값\n",
        "    change = s_l_loss_new - s_l_loss                                            # pseudo label 을 이용하기 전후의 Loss 값의 차이\n",
        "\n",
        "    t_l_pred = teacher(l_x)                                                     \n",
        "    t_l_loss = criterion(t_l_pred, l_y)                                         # teacher model 의 labeled data 에 대한 손실 계산\n",
        "\n",
        "    tl_loss.append(t_l_loss.item())                                             \n",
        "\n",
        "    t_mpl_loss = change * criterion(t_u_pred, pseudo_y)                         # unlabel data 에 대한 teacher model 의 손실 계산 - change 값을 점곱\n",
        "\n",
        "    (t_l_loss + t_mpl_loss).backward()                                          # teacher label loss 와 pseudo label loss를 이용해 역전파 수행\n",
        "    t_optimizer.step()                                                          # teacher model 의 parameter update\n",
        "\n",
        "#    if epochs+1 >= 250 and best_loss > s_l_loss.item():\n",
        "#        best_loss = s_l_loss.item()\n",
        "#        patient = 0\n",
        "#    elif epochs+1 >= 250 and best_loss <= s_l_loss.item():\n",
        "#        patient += 1\n",
        "#\n",
        "#    if patient == 20:\n",
        "#        early_stop_epoch = epochs + 1\n",
        "#\n",
        "#        torch.save(teacher.state_dict(), root_path+'/models/teacher/es_ratio_loss_teacher_state_dict.pt')\n",
        "#        torch.save(student.state_dict(), root_path+'/models/student/es_ratio_loss_student_state_dict.pt')"
      ],
      "metadata": {
        "id": "SnjzmFt5VMg2"
      },
      "id": "SnjzmFt5VMg2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# valid set 0.2 빼고, 나머지는 labeled, unlabeled 로 바꿔야 함"
      ],
      "metadata": {
        "id": "75Ixrm1K1JWc"
      },
      "id": "75Ixrm1K1JWc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89469d3b",
      "metadata": {
        "id": "89469d3b",
        "outputId": "fd9cacc5-76e9-485a-cb3b-6a7505a634cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Prepared.\n"
          ]
        }
      ],
      "source": [
        "## 결측치 제거를 한다면 아래 함수 실행 이전에 결측치 제거\n",
        "train_x, train_y, test_x = final_data_process(train_8, test_8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db2606c",
      "metadata": {
        "id": "4db2606c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97240cf5",
      "metadata": {
        "id": "97240cf5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}